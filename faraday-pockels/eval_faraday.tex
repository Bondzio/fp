\section{Evaluation for Faraday effect}
Now we fitted the plots with a leastsquare linear polynomial. 
The reasoning behind is, that the given standard deviations 
seem to be estimated much to high - one would expect more fluctuation 
around the fitted polynome. This observation can be made more 
precise using the $\chi^2$-test. For a variable $y_i$ in a sample of 
size $N$ assumed to follow 
a gaussian disribution around its expectation value, which in case of 
an underlying functional relation to another variable $x_i$ is assumed 
to be $\lambda(x_i; \theta)$, where $\theta$ are the parameters of 
the fit, we can define the quantity
\begin{equation}
    \chi^2(\theta) = \sum_{i, j= 1}^N (y_i - \lambda(x_i; \theta))
        (V^{-1}) (y_j - \lambda(x_j; \theta)), 
\end{equation}
where $V^{-1}$ is the inverse of the covariance matrix $\mathrm{cov}(i,j)$. 
The least square fit is done by simply minimizing the quantity. If the 
variables do follow the suspected functional relation and are distributed 
with a variance $\sigma_i^2$, then $chi^2$ should follow the 
$chi^2$-distribution with expectation value $n_d$, where $n_d$ is 
the number of points minus the number of paramter $\theta$.
One can thus test the applied hypothesis by calculating $chi^2$ and 
dividing it by $n_d$, getting a numerical value for the 
\emph{godness-of-fit}.
\begin{figure}
    \begin{centering}
        \includegraphics[width=18cm]{figures/fig21}
\captionsetup{singlelinecheck=off} 
\caption[.]{
\begin{eqnarray}
    \mathrm{cov}(p_i, p_j) &=& 
    \begin{pmatrix}
        4.511\mathrm{e}-04 &-1.127\mathrm{e}-03 \\
        -1.127\mathrm{e}-03 &3.824\mathrm{e}-03 \\
    \end{pmatrix}
\\ \Rightarrow \qquad
    p_1 &=& 2.561 \pm 0.021 \cm\\
    p_2 &=& 0.45 \pm 0.06 \cm \\ 
    \chi ^2/(N-1) &=&  0.092
\end{eqnarray}
}

    \end{centering}
\end{figure}
\begin{figure}
    \begin{centering}
        \includegraphics[width=18cm]{figures/fig22}
\captionsetup{singlelinecheck=off} 
\caption[.]{
\begin{eqnarray}
    \mathrm{cov}(p_i, p_j) &=& 
    \begin{pmatrix}
        3.835\mathrm{e}-03 &9.572\mathrm{e}-03 \\
        9.572\mathrm{e}-03 &3.245\mathrm{e}-02 \\
    \end{pmatrix}
\\ \Rightarrow \qquad
    p_1 &=& 2.53 \pm 0.06 \cm\\
    p_2 &=& 0.41 \pm 0.18 \cm \\
    \chi ^2/(N-1) &=& 0.114
\end{eqnarray}
}


%\label{fig:fig22}
    \end{centering}
\end{figure}

\begin{figure}
    \begin{centering}
        \includegraphics[width=18cm]{figures/fig23}
\captionsetup{singlelinecheck=off} 
\caption[.]{
\begin{eqnarray}
    \mathrm{cov}(p_i, p_j) &=& 
    \begin{pmatrix}
        1.443\mathrm{e}-04 &-3.391\mathrm{e}-04 \\
        -3.391\mathrm{e}-04 &1.014\mathrm{e}-03 \\
    \end{pmatrix}
\\ \Rightarrow \qquad
    p_1 &=& 2.606 \pm 0.012 \cm\\
    p_2 &=& 0.349 \pm 0.032 \cm \\
    \chi ^2/(N-1) &=&  0.020
\end{eqnarray}
}
    \end{centering}
\end{figure}

\begin{figure}
    \begin{centering}
        \includegraphics[width=18cm]{figures/fig24}
\captionsetup{singlelinecheck=off} 
\caption[.]{
\begin{eqnarray}
    \mathrm{cov}(p_i, p_j) &=& 
    \begin{pmatrix}
        3.310\mathrm{e}-04 &-7.931\mathrm{e}-04 \\
        -7.931\mathrm{e}-04 &2.582\mathrm{e}-03 \\
    \end{pmatrix}
\\ \Rightarrow \qquad
    p_1 &=& 2.561 \pm 0.018 \cm\\
    p_2 &=& 0.38 \pm 0.05 \cm \\
    \chi ^2/(N-1) &=&  0.060
\end{eqnarray}
}
    \end{centering}
\end{figure}


\begin{figure}
    \begin{centering}
        \includegraphics[width=18cm]{figures/fig_all}
\captionsetup{singlelinecheck=off} 
\caption[.]{
\begin{eqnarray}
    \mathrm{cov}(p_i, p_j) &=& 
    \begin{pmatrix}
        1.116\mathrm{e}-04 &-2.694\mathrm{e}-04 \\
        -2.694\mathrm{e}-04 &8.667\mathrm{e}-04 \\
    \end{pmatrix}
\\ \Rightarrow \qquad
    p_1 &=& 2.573 \pm 0.011 \cm\\
    p_2 &=& 0.398 \pm 0.029 \cm \\ 
    \chi ^2/(N-1) &=& 0.064
\end{eqnarray}
}
    \end{centering}
\end{figure}



